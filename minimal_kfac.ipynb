{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config import (\n",
    "    Config,\n",
    "    LinearModelConfig,\n",
    "    ModelConfig,\n",
    "    RandomRegressionConfig,\n",
    "    TrainingConfig,\n",
    "    TrainingConfig,\n",
    "    get_config,\n",
    ")\n",
    "from main import create_dataset_and_model, train_and_evaluate\n",
    "from data.data import create_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "from config.config import (\n",
    "    Config,\n",
    "    LinearModelConfig,\n",
    "    ModelConfig,\n",
    "    RandomRegressionConfig,\n",
    "    TrainingConfig,\n",
    "    TrainingConfig,\n",
    "    get_config,\n",
    ")\n",
    "from main import train_and_evaluate\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFAC api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-10-14 14:55:37,181:jax._src.xla_bridge:864: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "# config = get_config(\"random_regression_single_feature\")\n",
    "config = Config(\n",
    "    dataset=RandomRegressionConfig(\n",
    "        n_samples=100,\n",
    "        n_features=1,\n",
    "        n_targets=1,\n",
    "        noise=30,\n",
    "        random_state=42,\n",
    "        train_test_split=1,\n",
    "    ),\n",
    "    model=LinearModelConfig(\n",
    "        name=\"linear\", loss=\"mse\", hidden_dim=[10, 15, 30, 2, 4, 19, 10]\n",
    "    ),\n",
    "    training=TrainingConfig(\n",
    "        epochs=0,\n",
    "        lr=0.01,\n",
    "        optimizer=\"sgd\",\n",
    "        loss=\"mse\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "dataset = create_dataset(config.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfac import LinearModel\n",
    "\n",
    "model_kwargs = vars(config.model).copy()\n",
    "model_kwargs.pop(\"name\")\n",
    "model_kwargs.pop(\"loss\")\n",
    "model_kwargs.update(\n",
    "    {\"input_dim\": dataset.input_dim(), \"output_dim\": dataset.output_dim()}\n",
    ")\n",
    "\n",
    "model = LinearModel(**model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(42)\n",
    "params = model.init(key, jnp.ones((1, 1)))[\"params\"]\n",
    "\n",
    "dataset.split_dataset()\n",
    "x_train, y_train = dataset.get_train_data()\n",
    "x_train = jnp.array(x_train)\n",
    "y_train = jnp.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_with_capture(params, x, y, model, collector):\n",
    "    \"\"\"\n",
    "    Calculates the loss by calling the model's kfac_apply method.\n",
    "    \"\"\"\n",
    "    pred = model.apply(\n",
    "        {\"params\": params},\n",
    "        x,\n",
    "        collector,\n",
    "        method=model.kfac_apply,\n",
    "    )\n",
    "\n",
    "    return jnp.mean((pred - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_loss_fn(params, x, y, model):\n",
    "    \"\"\"Standard loss function without KFAC wrapper.\"\"\"\n",
    "    pred = model.apply({\"params\": params}, x)\n",
    "    return jnp.mean((pred.reshape(y.shape) - y) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 0 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss=1447.8220\n",
      "\n",
      "Final Optimizer State Covariances:\n"
     ]
    }
   ],
   "source": [
    "from kfac import KFACOptimizer, KFACCollector\n",
    "\n",
    "\n",
    "# This function does not need any changes.\n",
    "def train_step(params, opt_state, x, y):\n",
    "    collector = KFACCollector()\n",
    "    loss_fn_for_grad = lambda p: loss_fn_with_capture(p, x, y, model, collector)  # type: ignore\n",
    "\n",
    "    loss, grads = jax.value_and_grad(loss_fn_for_grad)(params)\n",
    "\n",
    "    captured_data_for_step = collector.captured_data\n",
    "\n",
    "    updated_params, new_opt_state = kfac_optimizer.step(\n",
    "        params, grads, opt_state, captured_data_for_step\n",
    "    )\n",
    "\n",
    "    return updated_params, new_opt_state, loss, collector\n",
    "\n",
    "\n",
    "# --- Let's run it again ---\n",
    "kfac_optimizer = KFACOptimizer()\n",
    "opt_state = kfac_optimizer.init(params)\n",
    "losses = []\n",
    "\n",
    "epochs = 3\n",
    "batch_size = 9\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n--- Epoch {epoch} ---\")\n",
    "    batch_x = x_train[epoch * batch_size : (epoch + 1) * batch_size]\n",
    "    batch_y = y_train[epoch * batch_size : (epoch + 1) * batch_size]\n",
    "\n",
    "    params, opt_state, loss, collector = train_step(params, opt_state, batch_x, batch_y)\n",
    "    ground_truth_grads = jax.grad(normal_loss_fn)(params, batch_x, batch_y, model)\n",
    "\n",
    "    losses.append(float(loss))\n",
    "    print(f\"Epoch {epoch}: loss={loss:.4f}\")\n",
    "    break\n",
    "\n",
    "print(\"\\nFinal Optimizer State Covariances:\")\n",
    "# Use jax.tree_map to print shapes for clarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[  6.169838  ,   9.5792    ,  -1.229347  ,   4.0899725 ,\n",
       "         -5.266316  ,   1.7055271 ,  -2.9594076 ,  -1.6442432 ,\n",
       "         -3.0903447 ,   7.8578806 ,   2.159025  , -11.400885  ,\n",
       "         -0.52694327,  -2.5515263 ,  -0.150404  ],\n",
       "       [  7.6029997 ,  11.804305  ,  -1.5149062 ,   5.0400124 ,\n",
       "         -6.489604  ,   2.101696  ,  -3.6468341 ,  -2.026177  ,\n",
       "         -3.8081863 ,   9.68315   ,   2.6605344 , -14.049141  ,\n",
       "         -0.6493444 ,  -3.1442084 ,  -0.18534063],\n",
       "       [  3.7146704 ,   5.767342  ,  -0.7401523 ,   2.4624472 ,\n",
       "         -3.170688  ,   1.0268458 ,  -1.7817687 ,  -0.9899487 ,\n",
       "         -1.860602  ,   4.7309895 ,   1.2998829 ,  -6.8641233 ,\n",
       "         -0.31725642,  -1.536196  ,  -0.09055365],\n",
       "       [ -4.5299573 ,  -7.0331445 ,   0.902599  ,  -3.0028987 ,\n",
       "          3.8665826 ,  -1.2522151 ,   2.1728265 ,   1.20722   ,\n",
       "          2.2689621 ,  -5.7693343 ,  -1.5851778 ,   8.370645  ,\n",
       "          0.38688704,   1.8733563 ,   0.11042814],\n",
       "       [  4.714502  ,   7.319666  ,  -0.9393698 ,   3.1252337 ,\n",
       "         -4.0241027 ,   1.3032289 ,  -2.2613451 ,  -1.2564007 ,\n",
       "         -2.3613973 ,   6.004371  ,   1.6497562 ,  -8.711655  ,\n",
       "         -0.4026484 ,  -1.9496747 ,  -0.11492685],\n",
       "       [ -3.86539   ,  -6.0013475 ,   0.77018327,  -2.5623589 ,\n",
       "          3.2993357 ,  -1.0685091 ,   1.8540623 ,   1.0301149 ,\n",
       "          1.9360944 ,  -4.9229455 ,  -1.3526244 ,   7.1426296 ,\n",
       "          0.3301288 ,   1.5985258 ,   0.09422778],\n",
       "       [  2.2120008 ,   3.43432   ,  -0.4407437 ,   1.4663309 ,\n",
       "         -1.888072  ,   0.6114631 ,  -1.0610024 ,  -0.5894917 ,\n",
       "         -1.1079458 ,   2.8171957 ,   0.77405035,  -4.0874286 ,\n",
       "         -0.18891893,  -0.91476953,  -0.05392262],\n",
       "       [ -3.7875764 ,  -5.8805356 ,   0.7546788 ,  -2.5107765 ,\n",
       "          3.2329175 ,  -1.0469991 ,   1.8167385 ,   1.0093778 ,\n",
       "          1.8971192 ,  -4.8238425 ,  -1.3253951 ,   6.9988427 ,\n",
       "          0.32348305,   1.5663462 ,   0.0923309 ],\n",
       "       [ -3.4734685 ,  -5.3928566 ,   0.69209254,  -2.3025553 ,\n",
       "          2.9648085 ,  -0.96017027,   1.6660744 ,   0.9256691 ,\n",
       "          1.739789  ,  -4.423795  ,  -1.2154785 ,   6.4184213 ,\n",
       "          0.29665625,   1.4364474 ,   0.08467381],\n",
       "       [  5.868972  ,   9.11208   ,  -1.1693993 ,   3.8905294 ,\n",
       "         -5.00951   ,   1.622359  ,  -2.8150947 ,  -1.5640635 ,\n",
       "         -2.9396472 ,   7.4746995 ,   2.0537422 , -10.844933  ,\n",
       "         -0.5012474 ,  -2.427104  ,  -0.1430697 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_grads[\"linear_1\"][\"kernel\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(ground_truth_grads.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n",
      "2.3841858e-07 8.791685e-07\n",
      "9.536743e-07 8.29529e-06\n",
      "1.9073486e-06 1.8246472e-05\n",
      "7.450581e-09 9.313226e-09\n",
      "9.536743e-07 5.3886324e-06\n",
      "4.7683716e-07 2.8163195e-06\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# outer product of a and g\n",
    "for key in keys:\n",
    "    a = collector.captured_data[key][0]\n",
    "    g = collector.captured_data[key][1]\n",
    "\n",
    "    ag = jnp.einsum(\"bi,bj->ij\", a, g)\n",
    "\n",
    "    diff = ag - ground_truth_grads[key][\"kernel\"]\n",
    "    print(jnp.abs(diff).max(), jnp.abs(diff).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0., dtype=float32), Array(0., dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# absolute value\n",
    "jnp.abs(diff).max(), jnp.abs(diff).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
