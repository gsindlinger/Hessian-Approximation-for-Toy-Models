base_output_dir: experiments/data/
dataset:
  name: energy
  path: experiments/datasets/energy
  store_on_disk: true
  test_size: 0.1
experiment_name: energy
models:
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 16
  - 16
  - 16
  - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 32
  - 32
  - 32
  - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 64
  - 64
  - 64
  - 64
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  - - 8
    - 8
    - 8
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  - - 16
    - 16
    - 16
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- activation: tanh
  architecture: mlp_swiglu
  directory: null
  hidden_dim:
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  - - 32
    - 32
    - 32
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
seed: 789
selection_metric: val_loss
selection_minimize: true
