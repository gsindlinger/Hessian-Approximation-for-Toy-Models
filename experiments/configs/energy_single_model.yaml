base_output_dir: experiments/data/
dataset:
  name: concrete
  path: experiments/datasets/concrete
  store_on_disk: true
  test_size: 0.1
experiment_name: energy_single_model
models:
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 1.0e-05
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0001
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.0005
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0001
    optimizer: adamw
    weight_decay: 0.001
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 1.0e-05
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0001
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.0005
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.0005
    optimizer: adamw
    weight_decay: 0.001
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 1.0e-05
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0001
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.0005
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.001
    optimizer: adamw
    weight_decay: 0.001
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 1.0e-05
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0001
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.0005
- architecture: mlp
  directory: null
  hidden_dim:
  - 128
  - 128
  input_dim: 8
  loss: mse
  output_dim: 2
  skip_existing: true
  training:
    batch_size: 32
    epochs: 500
    learning_rate: 0.005
    optimizer: adamw
    weight_decay: 0.001
seed: 42
selection_metric: val_loss
selection_minimize: true
